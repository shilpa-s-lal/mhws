{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf23a75e-9a0b-420f-a341-63a3ca1a6feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import geopandas as gpd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5175a8dd-ce87-4724-a6aa-902141a5b6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11254\n",
      "11254\n"
     ]
    }
   ],
   "source": [
    "# this cell is to make numeric values have 3 decimal places\n",
    "\n",
    "directory = '/media/shilpa/Expansion/ostia_mhw_cooks'\n",
    "coastal_files = [file for file in os.listdir(directory) if file.startswith(\"Cook Islands_spatial\")]\n",
    "\n",
    "# Read all CSV files and concatenate into a single DataFrame\n",
    "dfs = []\n",
    "for file in coastal_files:\n",
    "    # Handle file names with spaces by adding double quotes around the file path\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "float_cols = concatenated_df.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "concatenated_df[float_cols] = concatenated_df[float_cols].round(3)\n",
    "\n",
    "\n",
    "start_date = '1993-01-01'\n",
    "end_date = '2023-10-24'\n",
    "\n",
    "# Create datetime range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "print(len(date_range))\n",
    "\n",
    "concatenated_df['mapped_date'] = date_range[concatenated_df['time'] - concatenated_df['time'].min()].values\n",
    "\n",
    "concatenated_df.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/all_locations_intensity_severity_daily_country/cooks.csv')\n",
    "\n",
    "\n",
    "# Assuming the column containing presence and absence data is named 'presence'\n",
    "# Group by 'time' (assuming it's the column name) and calculate the percentage of presence for each day\n",
    "coastal_percentage = concatenated_df.groupby('time')['spatial_extent'].mean() * 100\n",
    "\n",
    "\n",
    "presence_df = pd.DataFrame({'time': coastal_percentage.index, 'coastal_percentage': coastal_percentage.values})\n",
    "\n",
    "float_cols_ = presence_df.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "presence_df[float_cols_] = presence_df[float_cols_].round(3)\n",
    "\n",
    "\n",
    "start_date = '1993-01-01'\n",
    "end_date = '2023-10-24'\n",
    "\n",
    "# Create datetime range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "print(len(date_range))\n",
    "\n",
    "\n",
    "presence_df = pd.DataFrame({'time': coastal_percentage.index,'time_dt':date_range.values, 'coastal_percentage': coastal_percentage.values})\n",
    "#filtered_df = presence_df[(presence_df['time_dt'] >= '1993-01-01') & (presence_df['time_dt'] <= '2014-12-31')]\n",
    "\n",
    "\n",
    "#coastal_cooks = filtered_df.replace(0,np.nan)\n",
    "\n",
    "presence_df.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/country_percent_coastal_mhw_extent/cooks.csv')\n",
    "\n",
    "\n",
    "coastal_files_ = [file for file in os.listdir(directory) if file.startswith(\"Cook Islands_mean\")]\n",
    "\n",
    "# Read all CSV files and concatenate into a single DataFrame\n",
    "dfs_ = []\n",
    "for file in coastal_files_:\n",
    "    # Handle file names with spaces by adding double quotes around the file path\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs_.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "concatenated_dfs_= pd.concat(dfs_, ignore_index=True)\n",
    "\n",
    "float_cols__ = concatenated_dfs_.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "concatenated_dfs_[float_cols__] = concatenated_dfs_[float_cols__].round(3)\n",
    "\n",
    "concatenated_dfs_.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/means_trends_all_location_country_coastal/cooks.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f1086d-8a2c-4b7e-a2b7-bf8df51aabd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11254\n",
      "11254\n"
     ]
    }
   ],
   "source": [
    "# this cell is to make numeric values have 3 decimal places\n",
    "\n",
    "directory = '/media/shilpa/Expansion/ostia_mhw_fiji'\n",
    "coastal_files = [file for file in os.listdir(directory) if file.startswith(\"Fiji_spatial\")]\n",
    "\n",
    "# Read all CSV files and concatenate into a single DataFrame\n",
    "dfs = []\n",
    "for file in coastal_files:\n",
    "    # Handle file names with spaces by adding double quotes around the file path\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "float_cols = concatenated_df.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "concatenated_df[float_cols] = concatenated_df[float_cols].round(3)\n",
    "\n",
    "\n",
    "start_date = '1993-01-01'\n",
    "end_date = '2023-10-24'\n",
    "\n",
    "# Create datetime range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "print(len(date_range))\n",
    "\n",
    "concatenated_df['mapped_date'] = date_range[concatenated_df['time'] - concatenated_df['time'].min()].values\n",
    "\n",
    "concatenated_df.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/all_locations_intensity_severity_daily_country/fiji.csv')\n",
    "\n",
    "\n",
    "# Assuming the column containing presence and absence data is named 'presence'\n",
    "# Group by 'time' (assuming it's the column name) and calculate the percentage of presence for each day\n",
    "coastal_percentage = concatenated_df.groupby('time')['spatial_extent'].mean() * 100\n",
    "\n",
    "\n",
    "presence_df = pd.DataFrame({'time': coastal_percentage.index, 'coastal_percentage': coastal_percentage.values})\n",
    "\n",
    "float_cols_ = presence_df.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "presence_df[float_cols_] = presence_df[float_cols_].round(3)\n",
    "\n",
    "\n",
    "start_date = '1993-01-01'\n",
    "end_date = '2023-10-24'\n",
    "\n",
    "# Create datetime range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "print(len(date_range))\n",
    "\n",
    "\n",
    "presence_df = pd.DataFrame({'time': coastal_percentage.index,'time_dt':date_range.values, 'coastal_percentage': coastal_percentage.values})\n",
    "#filtered_df = presence_df[(presence_df['time_dt'] >= '1993-01-01') & (presence_df['time_dt'] <= '2014-12-31')]\n",
    "\n",
    "\n",
    "#coastal_cooks = filtered_df.replace(0,np.nan)\n",
    "\n",
    "presence_df.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/country_percent_coastal_mhw_extent/fiji.csv')\n",
    "\n",
    "\n",
    "coastal_files_ = [file for file in os.listdir(directory) if file.startswith(\"Fiji_mean\")]\n",
    "\n",
    "# Read all CSV files and concatenate into a single DataFrame\n",
    "dfs_ = []\n",
    "for file in coastal_files_:\n",
    "    # Handle file names with spaces by adding double quotes around the file path\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs_.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "concatenated_dfs_= pd.concat(dfs_, ignore_index=True)\n",
    "\n",
    "float_cols__ = concatenated_dfs_.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "concatenated_dfs_[float_cols__] = concatenated_dfs_[float_cols__].round(3)\n",
    "\n",
    "concatenated_dfs_.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/means_trends_all_location_country_coastal/fiji.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "215d574a-32f4-4381-8753-2f03e4426a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11254\n",
      "11254\n"
     ]
    }
   ],
   "source": [
    "# this cell is to make numeric values have 3 decimal places\n",
    "\n",
    "directory = '/media/shilpa/Expansion/ostia_mhw_tonga'\n",
    "coastal_files = [file for file in os.listdir(directory) if file.startswith(\"Tonga_spatial\")]\n",
    "\n",
    "# Read all CSV files and concatenate into a single DataFrame\n",
    "dfs = []\n",
    "for file in coastal_files:\n",
    "    # Handle file names with spaces by adding double quotes around the file path\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "float_cols = concatenated_df.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "concatenated_df[float_cols] = concatenated_df[float_cols].round(3)\n",
    "\n",
    "\n",
    "start_date = '1993-01-01'\n",
    "end_date = '2023-10-24'\n",
    "\n",
    "# Create datetime range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "print(len(date_range))\n",
    "\n",
    "concatenated_df['mapped_date'] = date_range[concatenated_df['time'] - concatenated_df['time'].min()].values\n",
    "\n",
    "concatenated_df.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/all_locations_intensity_severity_daily_country/tonga.csv')\n",
    "\n",
    "\n",
    "# Assuming the column containing presence and absence data is named 'presence'\n",
    "# Group by 'time' (assuming it's the column name) and calculate the percentage of presence for each day\n",
    "coastal_percentage = concatenated_df.groupby('time')['spatial_extent'].mean() * 100\n",
    "\n",
    "\n",
    "presence_df = pd.DataFrame({'time': coastal_percentage.index, 'coastal_percentage': coastal_percentage.values})\n",
    "\n",
    "float_cols_ = presence_df.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "presence_df[float_cols_] = presence_df[float_cols_].round(3)\n",
    "\n",
    "\n",
    "start_date = '1993-01-01'\n",
    "end_date = '2023-10-24'\n",
    "\n",
    "# Create datetime range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "print(len(date_range))\n",
    "\n",
    "\n",
    "presence_df = pd.DataFrame({'time': coastal_percentage.index,'time_dt':date_range.values, 'coastal_percentage': coastal_percentage.values})\n",
    "#filtered_df = presence_df[(presence_df['time_dt'] >= '1993-01-01') & (presence_df['time_dt'] <= '2014-12-31')]\n",
    "\n",
    "\n",
    "#coastal_cooks = filtered_df.replace(0,np.nan)\n",
    "\n",
    "presence_df.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/country_percent_coastal_mhw_extent/tonga.csv')\n",
    "\n",
    "\n",
    "coastal_files_ = [file for file in os.listdir(directory) if file.startswith(\"Tonga_mean\")]\n",
    "\n",
    "# Read all CSV files and concatenate into a single DataFrame\n",
    "dfs_ = []\n",
    "for file in coastal_files_:\n",
    "    # Handle file names with spaces by adding double quotes around the file path\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs_.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "concatenated_dfs_= pd.concat(dfs_, ignore_index=True)\n",
    "\n",
    "float_cols__ = concatenated_dfs_.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "concatenated_dfs_[float_cols__] = concatenated_dfs_[float_cols__].round(3)\n",
    "\n",
    "concatenated_dfs_.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/means_trends_all_location_country_coastal/tonga.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad40328b-6ec4-402a-9b4f-85003e05b2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11254\n",
      "11254\n"
     ]
    }
   ],
   "source": [
    "# this cell is to make numeric values have 3 decimal places\n",
    "\n",
    "directory = '/media/shilpa/Expansion/ostia_mhw_vanuatu'\n",
    "coastal_files = [file for file in os.listdir(directory) if file.startswith(\"Vanuatu_spatial\")]\n",
    "\n",
    "# Read all CSV files and concatenate into a single DataFrame\n",
    "dfs = []\n",
    "for file in coastal_files:\n",
    "    # Handle file names with spaces by adding double quotes around the file path\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "float_cols = concatenated_df.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "concatenated_df[float_cols] = concatenated_df[float_cols].round(3)\n",
    "\n",
    "\n",
    "start_date = '1993-01-01'\n",
    "end_date = '2023-10-24'\n",
    "\n",
    "# Create datetime range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "print(len(date_range))\n",
    "\n",
    "concatenated_df['mapped_date'] = date_range[concatenated_df['time'] - concatenated_df['time'].min()].values\n",
    "\n",
    "concatenated_df.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/all_locations_intensity_severity_daily_country/vanuatu.csv')\n",
    "\n",
    "\n",
    "# Assuming the column containing presence and absence data is named 'presence'\n",
    "# Group by 'time' (assuming it's the column name) and calculate the percentage of presence for each day\n",
    "coastal_percentage = concatenated_df.groupby('time')['spatial_extent'].mean() * 100\n",
    "\n",
    "\n",
    "presence_df = pd.DataFrame({'time': coastal_percentage.index, 'coastal_percentage': coastal_percentage.values})\n",
    "\n",
    "float_cols_ = presence_df.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "presence_df[float_cols_] = presence_df[float_cols_].round(3)\n",
    "\n",
    "\n",
    "start_date = '1993-01-01'\n",
    "end_date = '2023-10-24'\n",
    "\n",
    "# Create datetime range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "print(len(date_range))\n",
    "\n",
    "\n",
    "presence_df = pd.DataFrame({'time': coastal_percentage.index,'time_dt':date_range.values, 'coastal_percentage': coastal_percentage.values})\n",
    "#filtered_df = presence_df[(presence_df['time_dt'] >= '1993-01-01') & (presence_df['time_dt'] <= '2014-12-31')]\n",
    "\n",
    "\n",
    "#coastal_cooks = filtered_df.replace(0,np.nan)\n",
    "\n",
    "presence_df.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/country_percent_coastal_mhw_extent/vanuatu.csv')\n",
    "\n",
    "\n",
    "coastal_files_ = [file for file in os.listdir(directory) if file.startswith(\"Vanuatu_mean\")]\n",
    "\n",
    "# Read all CSV files and concatenate into a single DataFrame\n",
    "dfs_ = []\n",
    "for file in coastal_files_:\n",
    "    # Handle file names with spaces by adding double quotes around the file path\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs_.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "concatenated_dfs_= pd.concat(dfs_, ignore_index=True)\n",
    "\n",
    "float_cols__ = concatenated_dfs_.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "concatenated_dfs_[float_cols__] = concatenated_dfs_[float_cols__].round(3)\n",
    "\n",
    "concatenated_dfs_.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/means_trends_all_location_country_coastal/vanuatu.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77b4e653-7ff3-4baf-a478-d80e9d5f3800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11254\n",
      "11254\n"
     ]
    }
   ],
   "source": [
    "# this cell is to make numeric values have 3 decimal places\n",
    "\n",
    "directory = '/media/shilpa/Expansion/ostia_mhw_wf'\n",
    "coastal_files = [file for file in os.listdir(directory) if file.startswith(\"Wallis and Futuna_spatial\")]\n",
    "\n",
    "# Read all CSV files and concatenate into a single DataFrame\n",
    "dfs = []\n",
    "for file in coastal_files:\n",
    "    # Handle file names with spaces by adding double quotes around the file path\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "float_cols = concatenated_df.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "concatenated_df[float_cols] = concatenated_df[float_cols].round(3)\n",
    "\n",
    "\n",
    "start_date = '1993-01-01'\n",
    "end_date = '2023-10-24'\n",
    "\n",
    "# Create datetime range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "print(len(date_range))\n",
    "\n",
    "concatenated_df['mapped_date'] = date_range[concatenated_df['time'] - concatenated_df['time'].min()].values\n",
    "\n",
    "concatenated_df.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/all_locations_intensity_severity_daily_country/wf.csv')\n",
    "\n",
    "\n",
    "# Assuming the column containing presence and absence data is named 'presence'\n",
    "# Group by 'time' (assuming it's the column name) and calculate the percentage of presence for each day\n",
    "coastal_percentage = concatenated_df.groupby('time')['spatial_extent'].mean() * 100\n",
    "\n",
    "\n",
    "presence_df = pd.DataFrame({'time': coastal_percentage.index, 'coastal_percentage': coastal_percentage.values})\n",
    "\n",
    "float_cols_ = presence_df.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "presence_df[float_cols_] = presence_df[float_cols_].round(3)\n",
    "\n",
    "\n",
    "start_date = '1993-01-01'\n",
    "end_date = '2023-10-24'\n",
    "\n",
    "# Create datetime range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "print(len(date_range))\n",
    "\n",
    "\n",
    "presence_df = pd.DataFrame({'time': coastal_percentage.index,'time_dt':date_range.values, 'coastal_percentage': coastal_percentage.values})\n",
    "#filtered_df = presence_df[(presence_df['time_dt'] >= '1993-01-01') & (presence_df['time_dt'] <= '2014-12-31')]\n",
    "\n",
    "\n",
    "#coastal_cooks = filtered_df.replace(0,np.nan)\n",
    "\n",
    "presence_df.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/country_percent_coastal_mhw_extent/wf.csv')\n",
    "\n",
    "\n",
    "coastal_files_ = [file for file in os.listdir(directory) if file.startswith(\"Wallis and Futuna_mean\")]\n",
    "\n",
    "# Read all CSV files and concatenate into a single DataFrame\n",
    "dfs_ = []\n",
    "for file in coastal_files_:\n",
    "    # Handle file names with spaces by adding double quotes around the file path\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs_.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "concatenated_dfs_= pd.concat(dfs_, ignore_index=True)\n",
    "\n",
    "float_cols__ = concatenated_dfs_.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "concatenated_dfs_[float_cols__] = concatenated_dfs_[float_cols__].round(3)\n",
    "\n",
    "concatenated_dfs_.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/means_trends_all_location_country_coastal/wf.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81a1bd72-254e-4cb6-891e-01fec9c06346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11254\n",
      "11254\n"
     ]
    }
   ],
   "source": [
    "# this cell is to make numeric values have 3 decimal places\n",
    "\n",
    "directory = '/media/shilpa/Expansion/ostia_mhw_samoa'\n",
    "coastal_files = [file for file in os.listdir(directory) if file.startswith(\"Samoa_spatial\")]\n",
    "\n",
    "# Read all CSV files and concatenate into a single DataFrame\n",
    "dfs = []\n",
    "for file in coastal_files:\n",
    "    # Handle file names with spaces by adding double quotes around the file path\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "float_cols = concatenated_df.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "concatenated_df[float_cols] = concatenated_df[float_cols].round(3)\n",
    "\n",
    "\n",
    "start_date = '1993-01-01'\n",
    "end_date = '2023-10-24'\n",
    "\n",
    "# Create datetime range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "print(len(date_range))\n",
    "\n",
    "concatenated_df['mapped_date'] = date_range[concatenated_df['time'] - concatenated_df['time'].min()].values\n",
    "\n",
    "concatenated_df.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/all_locations_intensity_severity_daily_country/samoa.csv')\n",
    "\n",
    "\n",
    "# Assuming the column containing presence and absence data is named 'presence'\n",
    "# Group by 'time' (assuming it's the column name) and calculate the percentage of presence for each day\n",
    "coastal_percentage = concatenated_df.groupby('time')['spatial_extent'].mean() * 100\n",
    "\n",
    "\n",
    "presence_df = pd.DataFrame({'time': coastal_percentage.index, 'coastal_percentage': coastal_percentage.values})\n",
    "\n",
    "float_cols_ = presence_df.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "presence_df[float_cols_] = presence_df[float_cols_].round(3)\n",
    "\n",
    "\n",
    "start_date = '1993-01-01'\n",
    "end_date = '2023-10-24'\n",
    "\n",
    "# Create datetime range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "print(len(date_range))\n",
    "\n",
    "\n",
    "presence_df = pd.DataFrame({'time': coastal_percentage.index,'time_dt':date_range.values, 'coastal_percentage': coastal_percentage.values})\n",
    "#filtered_df = presence_df[(presence_df['time_dt'] >= '1993-01-01') & (presence_df['time_dt'] <= '2014-12-31')]\n",
    "\n",
    "\n",
    "#coastal_cooks = filtered_df.replace(0,np.nan)\n",
    "\n",
    "presence_df.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/country_percent_coastal_mhw_extent/samoa.csv')\n",
    "\n",
    "\n",
    "coastal_files_ = [file for file in os.listdir(directory) if file.startswith(\"Samoa_mean\")]\n",
    "\n",
    "# Read all CSV files and concatenate into a single DataFrame\n",
    "dfs_ = []\n",
    "for file in coastal_files_:\n",
    "    # Handle file names with spaces by adding double quotes around the file path\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs_.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "concatenated_dfs_= pd.concat(dfs_, ignore_index=True)\n",
    "\n",
    "float_cols__ = concatenated_dfs_.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "concatenated_dfs_[float_cols__] = concatenated_dfs_[float_cols__].round(3)\n",
    "\n",
    "concatenated_dfs_.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/means_trends_all_location_country_coastal/samoa.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9115333e-7d0d-44f5-8d20-e62b146261d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11254\n",
      "11254\n"
     ]
    }
   ],
   "source": [
    "# this cell is to make numeric values have 3 decimal places\n",
    "\n",
    "directory = '/media/shilpa/Expansion/ostia_mhw_amsam'\n",
    "coastal_files = [file for file in os.listdir(directory) if file.startswith(\"American Samoa_spatial\")]\n",
    "\n",
    "# Read all CSV files and concatenate into a single DataFrame\n",
    "dfs = []\n",
    "for file in coastal_files:\n",
    "    # Handle file names with spaces by adding double quotes around the file path\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "float_cols = concatenated_df.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "concatenated_df[float_cols] = concatenated_df[float_cols].round(3)\n",
    "\n",
    "\n",
    "start_date = '1993-01-01'\n",
    "end_date = '2023-10-24'\n",
    "\n",
    "# Create datetime range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "print(len(date_range))\n",
    "\n",
    "concatenated_df['mapped_date'] = date_range[concatenated_df['time'] - concatenated_df['time'].min()].values\n",
    "\n",
    "concatenated_df.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/all_locations_intensity_severity_daily_country/am_samoa.csv')\n",
    "\n",
    "\n",
    "# Assuming the column containing presence and absence data is named 'presence'\n",
    "# Group by 'time' (assuming it's the column name) and calculate the percentage of presence for each day\n",
    "coastal_percentage = concatenated_df.groupby('time')['spatial_extent'].mean() * 100\n",
    "\n",
    "\n",
    "presence_df = pd.DataFrame({'time': coastal_percentage.index, 'coastal_percentage': coastal_percentage.values})\n",
    "\n",
    "float_cols_ = presence_df.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "presence_df[float_cols_] = presence_df[float_cols_].round(3)\n",
    "\n",
    "\n",
    "start_date = '1993-01-01'\n",
    "end_date = '2023-10-24'\n",
    "\n",
    "# Create datetime range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "print(len(date_range))\n",
    "\n",
    "\n",
    "presence_df = pd.DataFrame({'time': coastal_percentage.index,'time_dt':date_range.values, 'coastal_percentage': coastal_percentage.values})\n",
    "#filtered_df = presence_df[(presence_df['time_dt'] >= '1993-01-01') & (presence_df['time_dt'] <= '2014-12-31')]\n",
    "\n",
    "\n",
    "#coastal_cooks = filtered_df.replace(0,np.nan)\n",
    "\n",
    "presence_df.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/country_percent_coastal_mhw_extent/am_samoa.csv')\n",
    "\n",
    "\n",
    "coastal_files_ = [file for file in os.listdir(directory) if file.startswith(\"American Samoa_mean\")]\n",
    "\n",
    "# Read all CSV files and concatenate into a single DataFrame\n",
    "dfs_ = []\n",
    "for file in coastal_files_:\n",
    "    # Handle file names with spaces by adding double quotes around the file path\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs_.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "concatenated_dfs_= pd.concat(dfs_, ignore_index=True)\n",
    "\n",
    "float_cols__ = concatenated_dfs_.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "concatenated_dfs_[float_cols__] = concatenated_dfs_[float_cols__].round(3)\n",
    "\n",
    "concatenated_dfs_.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/means_trends_all_location_country_coastal/am_samoa.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "912c0f79-13e9-45c5-93dc-e0b8e2d7965c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11254\n",
      "11254\n"
     ]
    }
   ],
   "source": [
    "# this cell is to make numeric values have 3 decimal places\n",
    "\n",
    "directory = '/media/shilpa/Expansion/ostia_mhw_niue'\n",
    "coastal_files = [file for file in os.listdir(directory) if file.startswith(\"Niue_spatial\")]\n",
    "\n",
    "# Read all CSV files and concatenate into a single DataFrame\n",
    "dfs = []\n",
    "for file in coastal_files:\n",
    "    # Handle file names with spaces by adding double quotes around the file path\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "float_cols = concatenated_df.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "concatenated_df[float_cols] = concatenated_df[float_cols].round(3)\n",
    "\n",
    "\n",
    "start_date = '1993-01-01'\n",
    "end_date = '2023-10-24'\n",
    "\n",
    "# Create datetime range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "print(len(date_range))\n",
    "\n",
    "concatenated_df['mapped_date'] = date_range[concatenated_df['time'] - concatenated_df['time'].min()].values\n",
    "\n",
    "concatenated_df.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/all_locations_intensity_severity_daily_country/niue.csv')\n",
    "\n",
    "\n",
    "# Assuming the column containing presence and absence data is named 'presence'\n",
    "# Group by 'time' (assuming it's the column name) and calculate the percentage of presence for each day\n",
    "coastal_percentage = concatenated_df.groupby('time')['spatial_extent'].mean() * 100\n",
    "\n",
    "\n",
    "presence_df = pd.DataFrame({'time': coastal_percentage.index, 'coastal_percentage': coastal_percentage.values})\n",
    "\n",
    "float_cols_ = presence_df.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "presence_df[float_cols_] = presence_df[float_cols_].round(3)\n",
    "\n",
    "\n",
    "start_date = '1993-01-01'\n",
    "end_date = '2023-10-24'\n",
    "\n",
    "# Create datetime range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "print(len(date_range))\n",
    "\n",
    "\n",
    "presence_df = pd.DataFrame({'time': coastal_percentage.index,'time_dt':date_range.values, 'coastal_percentage': coastal_percentage.values})\n",
    "#filtered_df = presence_df[(presence_df['time_dt'] >= '1993-01-01') & (presence_df['time_dt'] <= '2014-12-31')]\n",
    "\n",
    "\n",
    "#coastal_cooks = filtered_df.replace(0,np.nan)\n",
    "\n",
    "presence_df.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/country_percent_coastal_mhw_extent/niue.csv')\n",
    "\n",
    "\n",
    "coastal_files_ = [file for file in os.listdir(directory) if file.startswith(\"Niue_mean\")]\n",
    "\n",
    "# Read all CSV files and concatenate into a single DataFrame\n",
    "dfs_ = []\n",
    "for file in coastal_files_:\n",
    "    # Handle file names with spaces by adding double quotes around the file path\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs_.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "concatenated_dfs_= pd.concat(dfs_, ignore_index=True)\n",
    "\n",
    "float_cols__ = concatenated_dfs_.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "concatenated_dfs_[float_cols__] = concatenated_dfs_[float_cols__].round(3)\n",
    "\n",
    "concatenated_dfs_.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/means_trends_all_location_country_coastal/niue.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e318f4f-aaf3-40b2-97ec-3e3b79cafbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11254\n",
      "11254\n"
     ]
    }
   ],
   "source": [
    "# this cell is to make numeric values have 3 decimal places\n",
    "\n",
    "directory = '/media/shilpa/Expansion/ostia_mhw_tokelau'\n",
    "coastal_files = [file for file in os.listdir(directory) if file.startswith(\"Tokelau_spatial\")]\n",
    "\n",
    "# Read all CSV files and concatenate into a single DataFrame\n",
    "dfs = []\n",
    "for file in coastal_files:\n",
    "    # Handle file names with spaces by adding double quotes around the file path\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "float_cols = concatenated_df.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "concatenated_df[float_cols] = concatenated_df[float_cols].round(3)\n",
    "\n",
    "\n",
    "start_date = '1993-01-01'\n",
    "end_date = '2023-10-24'\n",
    "\n",
    "# Create datetime range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "print(len(date_range))\n",
    "\n",
    "concatenated_df['mapped_date'] = date_range[concatenated_df['time'] - concatenated_df['time'].min()].values\n",
    "\n",
    "concatenated_df.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/all_locations_intensity_severity_daily_country/tokelau.csv')\n",
    "\n",
    "\n",
    "# Assuming the column containing presence and absence data is named 'presence'\n",
    "# Group by 'time' (assuming it's the column name) and calculate the percentage of presence for each day\n",
    "coastal_percentage = concatenated_df.groupby('time')['spatial_extent'].mean() * 100\n",
    "\n",
    "\n",
    "presence_df = pd.DataFrame({'time': coastal_percentage.index, 'coastal_percentage': coastal_percentage.values})\n",
    "\n",
    "float_cols_ = presence_df.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "presence_df[float_cols_] = presence_df[float_cols_].round(3)\n",
    "\n",
    "\n",
    "start_date = '1993-01-01'\n",
    "end_date = '2023-10-24'\n",
    "\n",
    "# Create datetime range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "print(len(date_range))\n",
    "\n",
    "\n",
    "presence_df = pd.DataFrame({'time': coastal_percentage.index,'time_dt':date_range.values, 'coastal_percentage': coastal_percentage.values})\n",
    "#filtered_df = presence_df[(presence_df['time_dt'] >= '1993-01-01') & (presence_df['time_dt'] <= '2014-12-31')]\n",
    "\n",
    "\n",
    "#coastal_cooks = filtered_df.replace(0,np.nan)\n",
    "\n",
    "presence_df.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/country_percent_coastal_mhw_extent/tokelau.csv')\n",
    "\n",
    "\n",
    "coastal_files_ = [file for file in os.listdir(directory) if file.startswith(\"Tokelau_mean\")]\n",
    "\n",
    "# Read all CSV files and concatenate into a single DataFrame\n",
    "dfs_ = []\n",
    "for file in coastal_files_:\n",
    "    # Handle file names with spaces by adding double quotes around the file path\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs_.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "concatenated_dfs_= pd.concat(dfs_, ignore_index=True)\n",
    "\n",
    "float_cols__ = concatenated_dfs_.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "concatenated_dfs_[float_cols__] = concatenated_dfs_[float_cols__].round(3)\n",
    "\n",
    "concatenated_dfs_.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/means_trends_all_location_country_coastal/tokelau.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4daa6a7-2796-4fc8-a4aa-6dd532d3def0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11254\n",
      "11254\n"
     ]
    }
   ],
   "source": [
    "# this cell is to make numeric values have 3 decimal places\n",
    "\n",
    "directory = '/media/shilpa/Expansion/ostia_mhw_tuvalu'\n",
    "coastal_files = [file for file in os.listdir(directory) if file.startswith(\"Tuvalu_spatial\")]\n",
    "\n",
    "# Read all CSV files and concatenate into a single DataFrame\n",
    "dfs = []\n",
    "for file in coastal_files:\n",
    "    # Handle file names with spaces by adding double quotes around the file path\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "float_cols = concatenated_df.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "concatenated_df[float_cols] = concatenated_df[float_cols].round(3)\n",
    "\n",
    "\n",
    "start_date = '1993-01-01'\n",
    "end_date = '2023-10-24'\n",
    "\n",
    "# Create datetime range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "print(len(date_range))\n",
    "\n",
    "concatenated_df['mapped_date'] = date_range[concatenated_df['time'] - concatenated_df['time'].min()].values\n",
    "\n",
    "concatenated_df.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/all_locations_intensity_severity_daily_country/tuvalu.csv')\n",
    "\n",
    "\n",
    "# Assuming the column containing presence and absence data is named 'presence'\n",
    "# Group by 'time' (assuming it's the column name) and calculate the percentage of presence for each day\n",
    "coastal_percentage = concatenated_df.groupby('time')['spatial_extent'].mean() * 100\n",
    "\n",
    "\n",
    "presence_df = pd.DataFrame({'time': coastal_percentage.index, 'coastal_percentage': coastal_percentage.values})\n",
    "\n",
    "float_cols_ = presence_df.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "presence_df[float_cols_] = presence_df[float_cols_].round(3)\n",
    "\n",
    "\n",
    "start_date = '1993-01-01'\n",
    "end_date = '2023-10-24'\n",
    "\n",
    "# Create datetime range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "print(len(date_range))\n",
    "\n",
    "\n",
    "presence_df = pd.DataFrame({'time': coastal_percentage.index,'time_dt':date_range.values, 'coastal_percentage': coastal_percentage.values})\n",
    "#filtered_df = presence_df[(presence_df['time_dt'] >= '1993-01-01') & (presence_df['time_dt'] <= '2014-12-31')]\n",
    "\n",
    "\n",
    "#coastal_cooks = filtered_df.replace(0,np.nan)\n",
    "\n",
    "presence_df.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/country_percent_coastal_mhw_extent/tuvalu.csv')\n",
    "\n",
    "\n",
    "coastal_files_ = [file for file in os.listdir(directory) if file.startswith(\"Tuvalu_mean\")]\n",
    "\n",
    "# Read all CSV files and concatenate into a single DataFrame\n",
    "dfs_ = []\n",
    "for file in coastal_files_:\n",
    "    # Handle file names with spaces by adding double quotes around the file path\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs_.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "concatenated_dfs_= pd.concat(dfs_, ignore_index=True)\n",
    "\n",
    "float_cols__ = concatenated_dfs_.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "concatenated_dfs_[float_cols__] = concatenated_dfs_[float_cols__].round(3)\n",
    "\n",
    "concatenated_dfs_.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/means_trends_all_location_country_coastal/tuvalu.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83c2a77f-0270-4dc5-b182-21a45b4cb164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11254\n",
      "11254\n"
     ]
    }
   ],
   "source": [
    "# this cell is to make numeric values have 3 decimal places\n",
    "\n",
    "directory = '/media/shilpa/Expansion/ostia_mhw_solo'\n",
    "coastal_files = [file for file in os.listdir(directory) if file.startswith(\"Solomon Islands_spatial\")]\n",
    "\n",
    "# Read all CSV files and concatenate into a single DataFrame\n",
    "dfs = []\n",
    "for file in coastal_files:\n",
    "    # Handle file names with spaces by adding double quotes around the file path\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "float_cols = concatenated_df.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "concatenated_df[float_cols] = concatenated_df[float_cols].round(3)\n",
    "\n",
    "\n",
    "start_date = '1993-01-01'\n",
    "end_date = '2023-10-24'\n",
    "\n",
    "# Create datetime range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "print(len(date_range))\n",
    "\n",
    "concatenated_df['mapped_date'] = date_range[concatenated_df['time'] - concatenated_df['time'].min()].values\n",
    "\n",
    "concatenated_df.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/all_locations_intensity_severity_daily_country/solo.csv')\n",
    "\n",
    "\n",
    "# Assuming the column containing presence and absence data is named 'presence'\n",
    "# Group by 'time' (assuming it's the column name) and calculate the percentage of presence for each day\n",
    "coastal_percentage = concatenated_df.groupby('time')['spatial_extent'].mean() * 100\n",
    "\n",
    "\n",
    "presence_df = pd.DataFrame({'time': coastal_percentage.index, 'coastal_percentage': coastal_percentage.values})\n",
    "\n",
    "float_cols_ = presence_df.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "presence_df[float_cols_] = presence_df[float_cols_].round(3)\n",
    "\n",
    "\n",
    "start_date = '1993-01-01'\n",
    "end_date = '2023-10-24'\n",
    "\n",
    "# Create datetime range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "print(len(date_range))\n",
    "\n",
    "\n",
    "presence_df = pd.DataFrame({'time': coastal_percentage.index,'time_dt':date_range.values, 'coastal_percentage': coastal_percentage.values})\n",
    "#filtered_df = presence_df[(presence_df['time_dt'] >= '1993-01-01') & (presence_df['time_dt'] <= '2014-12-31')]\n",
    "\n",
    "\n",
    "#coastal_cooks = filtered_df.replace(0,np.nan)\n",
    "\n",
    "presence_df.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/country_percent_coastal_mhw_extent/solo.csv')\n",
    "\n",
    "\n",
    "coastal_files_ = [file for file in os.listdir(directory) if file.startswith(\"Solomon Islands_mean\")]\n",
    "\n",
    "# Read all CSV files and concatenate into a single DataFrame\n",
    "dfs_ = []\n",
    "for file in coastal_files_:\n",
    "    # Handle file names with spaces by adding double quotes around the file path\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs_.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "concatenated_dfs_= pd.concat(dfs_, ignore_index=True)\n",
    "\n",
    "float_cols__ = concatenated_dfs_.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "concatenated_dfs_[float_cols__] = concatenated_dfs_[float_cols__].round(3)\n",
    "\n",
    "concatenated_dfs_.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/means_trends_all_location_country_coastal/solo.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ad48c95-c5f5-4769-871b-9f0fec527b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11254\n",
      "11254\n"
     ]
    }
   ],
   "source": [
    "# this cell is to make numeric values have 3 decimal places\n",
    "\n",
    "directory = '/media/shilpa/Expansion/ostia_mhw_newcal'\n",
    "coastal_files = [file for file in os.listdir(directory) if file.startswith(\"New Caledonia_spatial\")]\n",
    "\n",
    "# Read all CSV files and concatenate into a single DataFrame\n",
    "dfs = []\n",
    "for file in coastal_files:\n",
    "    # Handle file names with spaces by adding double quotes around the file path\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "float_cols = concatenated_df.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "concatenated_df[float_cols] = concatenated_df[float_cols].round(3)\n",
    "\n",
    "\n",
    "start_date = '1993-01-01'\n",
    "end_date = '2023-10-24'\n",
    "\n",
    "# Create datetime range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "print(len(date_range))\n",
    "\n",
    "concatenated_df['mapped_date'] = date_range[concatenated_df['time'] - concatenated_df['time'].min()].values\n",
    "\n",
    "concatenated_df.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/all_locations_intensity_severity_daily_country/newcal.csv')\n",
    "\n",
    "\n",
    "# Assuming the column containing presence and absence data is named 'presence'\n",
    "# Group by 'time' (assuming it's the column name) and calculate the percentage of presence for each day\n",
    "coastal_percentage = concatenated_df.groupby('time')['spatial_extent'].mean() * 100\n",
    "\n",
    "\n",
    "presence_df = pd.DataFrame({'time': coastal_percentage.index, 'coastal_percentage': coastal_percentage.values})\n",
    "\n",
    "float_cols_ = presence_df.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "presence_df[float_cols_] = presence_df[float_cols_].round(3)\n",
    "\n",
    "\n",
    "start_date = '1993-01-01'\n",
    "end_date = '2023-10-24'\n",
    "\n",
    "# Create datetime range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "print(len(date_range))\n",
    "\n",
    "\n",
    "presence_df = pd.DataFrame({'time': coastal_percentage.index,'time_dt':date_range.values, 'coastal_percentage': coastal_percentage.values})\n",
    "#filtered_df = presence_df[(presence_df['time_dt'] >= '1993-01-01') & (presence_df['time_dt'] <= '2014-12-31')]\n",
    "\n",
    "\n",
    "#coastal_cooks = filtered_df.replace(0,np.nan)\n",
    "\n",
    "presence_df.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/country_percent_coastal_mhw_extent/newcal.csv')\n",
    "\n",
    "\n",
    "coastal_files_ = [file for file in os.listdir(directory) if file.startswith(\"New Caledonia_mean\")]\n",
    "\n",
    "# Read all CSV files and concatenate into a single DataFrame\n",
    "dfs_ = []\n",
    "for file in coastal_files_:\n",
    "    # Handle file names with spaces by adding double quotes around the file path\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs_.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "concatenated_dfs_= pd.concat(dfs_, ignore_index=True)\n",
    "\n",
    "float_cols__ = concatenated_dfs_.select_dtypes(include='float').columns.difference(['latitude', 'longitude'])\n",
    "\n",
    "# Round those float columns to 3 decimals\n",
    "concatenated_dfs_[float_cols__] = concatenated_dfs_[float_cols__].round(3)\n",
    "\n",
    "concatenated_dfs_.to_csv('/media/shilpa/Expansion/ostia_coastal_mhws_pacific_datahub_3deci_places/means_trends_all_location_country_coastal/newcal.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382f271a-d1c6-4676-854c-78817f780608",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
